import { Router, Request, Response } from 'express';
// In a real app, you would use an actual LLM client, e.g., from '@google/generative-ai'
// import { GoogleGenerativeAI } from '@google/generative-ai';
import pool from '../database';

const router = Router();

// const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);

router.post('/generate/character', async (req: Request, res: Response) => {
  const { prompt, contextId } = req.body;

  if (!prompt || !contextId) {
    return res.status(400).json({ error: 'Prompt and contextId are required.' });
  }

  try {
    // 1. Construct Context (as described in the design document)
    // This is a simplified version. A real implementation would recursively
    // fetch parent contexts to build a full narrative hierarchy.
    const contextRes = await pool.query('SELECT * FROM Contexts WHERE context_id = $1', [contextId]);
    const roomRes = await pool.query('SELECT * FROM MapElements WHERE element_id = $1', [contextId]);

    const context = {
      campaign: { name: 'The Lost Mines of Phandelver' }, // Mock campaign data
      location: contextRes.rows[0],
      room: roomRes.rows[0],
    };

    // 2. Assemble Prompt (Simplified)
    const finalPrompt = `
      Campaign: ${context.campaign.name}
      Location: ${context.location?.name} (${context.location?.description})
      Room: ${context.room?.data.label} (${context.room?.data.description})
      ---
      User Request: Generate a character based on the following: "${prompt}"
      ---
      Return a JSON object with keys: "name", "description", "stats".
    `;

    console.log('--- Assembled Prompt ---');
    console.log(finalPrompt);

    // 3. Call LLM (Mocked) & 4. Process Response
    // In a real implementation, you would make the API call here:
    // const result = await genAI.getGenerativeModel({ model: "gemini-pro" }).generateContent(finalPrompt);
    // const characterData = JSON.parse(result.response.text());
    const mockCharacterData = {
      name: `Generated Character: ${prompt.substring(0, 20)}`,
      description: 'A character generated by the mighty LLM, with a story yet to be told.',
      stats: { str: 10, dex: 12, con: 14, int: 8, wis: 13, cha: 16 },
    };

    // 5. Persist Data
    const { rows } = await pool.query(
      `INSERT INTO MapElements (campaign_id, context_id, parent_element_id, type, position_x, position_y, data)
       VALUES ($1, $2, $3, 'character', $4, $5, $6) RETURNING *`,
      [1, context.location?.context_id, context.room?.element_id, 150, 250, mockCharacterData] // Mocked campaign_id and position
    );

    // 6. Send Response
    res.status(201).json(rows[0]);

  } catch (err) {
    console.error('Character generation failed:', err);
    res.status(500).json({ error: 'Internal server error' });
  }
});

export default router; 